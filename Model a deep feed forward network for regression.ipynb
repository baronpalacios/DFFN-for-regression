{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###                                  <center> CSE555 – Deep Learning (Spring 2018) center\n",
    "###                                               <center> Homework 1 </center>\n",
    "### <center>Part 1: Model a deep feed forward network for regression</center>\n",
    "###                                    <center>   Harlinton Palacios Mosquera </center>\n",
    "                                   \n",
    "###                                       <center>  ID: 161041033  </center>                                        \n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import losses\n",
    "from keras.layers import Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I created a baseline neural network model for the regression problem. Let’s start off by including all of the functions and objects we will need for this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 370\n",
    "insize = 1\n",
    "batch  = 75\n",
    "n = 936\n",
    "\n",
    "n_train= int(n*0.8)\n",
    "n_test = int(n*0.2)\n",
    "x_train=np.random.rand(900)\n",
    "y_train=x_train**4+x_train**3-x_train\n",
    "x_train=x_train.reshape(len(x_train),1)\n",
    "x_test=np.linspace(0,1,100)\n",
    "y_test=x_test**4+x_test**3-x_test\n",
    "x_test=x_test.reshape(len(x_test),1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> Here I generated my data from a polynomial of fourth degree with the help of the package (Panda.rondom). I also define some variables for the percentage of data to train, to test the neural network, the number of Epochs, number of input data and Batch number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Create_network(): \n",
    "    network = Sequential()\n",
    "    network.add(Dense(5, input_dim=insize, kernel_initializer=\"normal\", activation=\"elu\"))\n",
    "    network.add(Dense(5, kernel_initializer=\"normal\", activation=\"relu\"))\n",
    "    network.add(Dense(5, kernel_initializer=\"normal\", activation=\"relu\"))\n",
    "    network.add(Dense(1, activation=\"sigmoid\"))  \n",
    "   \n",
    "    network.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "    #network.compile(loss=\"mean_squared_error\", optimizer=\"Adamax\")\n",
    "     #network.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")\n",
    "    #network.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "    #network.compile(loss='mean_squared_error',optimizer=sgd,metrics=['mae', 'acc'])\n",
    "    return network\n",
    "\n",
    "network = Create_network()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Comment:</b> Here I defined the function to create the model of the nueronal network. It is a model that has 4 hidden layers totally connected and the activation parameter is (Relu) and the activation parameter of the neuron of output is (Linear). The first thing the network used was an activation function of the rectifier for the hidden layer, which is called the SGD optimization algorithm, it is used efficiently and a quadratic error loss function is optimized, this will be the same measure that we will use for evaluate the performance of the model and MSE Calculate the average square error rate between the predicted and target values.\n",
    "\n",
    "That's the first network model.\n",
    "<img src=\"https://image.ibb.co/g08DoS/Screenshot_from_2018_03_09_09_06_16.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "That's the final network model.\n",
    "<img src=\"https://image.ibb.co/mZY2hn/Screenshot_from_2018_03_09_09_03_54.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 602 samples, validate on 298 samples\n",
      "Epoch 1/370\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(75, 1), b.shape=(1, 5), m=75, n=5, k=1\n\t [[Node: dense_1/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_dense_1_input_0/_87, dense_1/kernel/read)]]\n\t [[Node: loss/mul/_119 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_513_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'dense_1/MatMul', defined at:\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-12006b3de999>\", line 15, in <module>\n    network = Create_network()\n  File \"<ipython-input-3-12006b3de999>\", line 3, in Create_network\n    network.add(Dense(5, input_dim=insize, kernel_initializer=\"normal\", activation=\"elu\"))\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\keras\\models.py\", line 467, in add\n    layer(x)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\keras\\layers\\core.py\", line 855, in call\n    output = K.dot(inputs, self.kernel)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1075, in dot\n    out = tf.matmul(x, y)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1801, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1263, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(75, 1), b.shape=(1, 5), m=75, n=5, k=1\n\t [[Node: dense_1/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_dense_1_input_0/_87, dense_1/kernel/read)]]\n\t [[Node: loss/mul/_119 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_513_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(75, 1), b.shape=(1, 5), m=75, n=5, k=1\n\t [[Node: dense_1/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_dense_1_input_0/_87, dense_1/kernel/read)]]\n\t [[Node: loss/mul/_119 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_513_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalError\u001b[0m               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a666a28eb171>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(75, 1), b.shape=(1, 5), m=75, n=5, k=1\n\t [[Node: dense_1/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_dense_1_input_0/_87, dense_1/kernel/read)]]\n\t [[Node: loss/mul/_119 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_513_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'dense_1/MatMul', defined at:\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-12006b3de999>\", line 15, in <module>\n    network = Create_network()\n  File \"<ipython-input-3-12006b3de999>\", line 3, in Create_network\n    network.add(Dense(5, input_dim=insize, kernel_initializer=\"normal\", activation=\"elu\"))\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\keras\\models.py\", line 467, in add\n    layer(x)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\keras\\layers\\core.py\", line 855, in call\n    output = K.dot(inputs, self.kernel)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1075, in dot\n    out = tf.matmul(x, y)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1801, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1263, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(75, 1), b.shape=(1, 5), m=75, n=5, k=1\n\t [[Node: dense_1/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_dense_1_input_0/_87, dense_1/kernel/read)]]\n\t [[Node: loss/mul/_119 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_513_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "history = network.fit( x_train, y_train, batch_size=batch, epochs=epoch, verbose=1, validation_split=0.33)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I train the specified model some parameters \n",
    " like epochs number: Number of epochs to train the model\n",
    " lot size: Number of samples per gradient update\n",
    " training variables x_train, y_train: Numpy array of training data\n",
    " validation_split: Fraction of the training data to be used as validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 190us/step\n",
      "\n",
      "Loss: 0.11\n"
     ]
    }
   ],
   "source": [
    "historyval = network.evaluate(x_test, y_test, batch_size=batch, verbose=1)\n",
    "print(\"\\nLoss: %.2f\" % (historyval))\n",
    "predi = network.predict(x_test, batch_size=batch, verbose=0, steps=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, carry out the evaluation of the network, specifying the necessary parameters, such as the variables for their respective evaluation, which has a resevated percentage of the initial data. there is also a parameter to print the result of the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7eff5c259160>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndh1wAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7eff5c22c588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(history.history.keys())\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Perdiction Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I obtain the results of the data of the varibals. Val_loss is the value of the cost function for the cross-validation data and the loss is the value of the cost function for your training data and with these results graph the graph where it shows the comparison of the performance of the neural network in training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reports step by step:\n",
    "## <b>Point 5: Parameters used:</b> \n",
    "Neural network: It has 4 hidden layers,they use the same activation function (tanh), the SGD optimizer was used, mean_squared_error(MSE) also loss function and Epochs number was 200, Batchs number was 50. with these parameters this result was obtained:\n",
    "### I got  loss = 0.11\n",
    "<img src=\"https://image.ibb.co/e64sV7/1.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "### <b>Point 6: Parameters used:</b> \n",
    " ### <b>First combination used:</b>\n",
    " The (rmsprop) optimizer, changed Epoch number was 250 and Batchs number was 70 and used activation funtion (tanh) <b>I got Loss: 0.16</b>\n",
    " ### <b>second combination used:</b>\n",
    " The (adam) optimizer, changed Epoch number was 375(+50%) and Batchs number was 75 and used activation funtion (selu):Scaled Exponential Linear Unit  <b>I got Loss: 0.10</b>\n",
    "  ### <b>third combination used:</b>\n",
    " The (Adamax) optimizer, changed Epoch number was 375(+50%) and Batchs number was 60 and used activation funtion (elu):<b> I got Loss: 0.014</b>\n",
    " \n",
    "### <b>Point 7:</b>  \n",
    "## According to the results obtained during these 3 combinations, the best combination was the second in which a much faster and less expensive result was obtained where the variable Loss was 0.10\n",
    "\n",
    "\n",
    "# <b>Point 8: Parameters used:</b> \n",
    "\n",
    "## #--The first hidden layer, add one node\n",
    "-This time I added a node to the first layer, which was with 5 nodes one more than the other 3 educated layers and the result of the variable Loss did not change much, only increased 0.01 more.\n",
    " <img src=\"https://image.ibb.co/dFBMQ7/Screenshot_from_2018_03_09_06_04_30.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "  <img src=\"https://image.ibb.co/e4zEdS/Screenshot_from_2018_03_09_06_47_51.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "## #--The secund hidden layer, add one node\n",
    "-This time I added a node to the second layer, in total it has 5 nodes. when adding this new node I do not see difference in the result, the loss variable obtained 0.11 igulates that the last result\n",
    " <img src=\"https://image.ibb.co/f9t7yS/Screenshot_from_2018_03_09_06_16_52.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    " <img src=\"https://image.ibb.co/kuxWsn/Screenshot_from_2018_03_09_07_19_00.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    " \n",
    "\n",
    "## #--The third hidden layer, add one node\n",
    "This time I added a node to the trird layer, in total it has 5 nodes. when adding this new node I do not see difference in the result, the loss variable obtained 0.11 igulates that the last result\n",
    " <img src=\"https://image.ibb.co/cvZY57/Screenshot_from_2018_03_09_06_29_45.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    " <img src=\"https://image.ibb.co/fOjxF7/Screenshot_from_2018_03_09_07_33_02.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    " \n",
    " \n",
    " \n",
    " # <b>Point 9: I entered the value of (Nt) 4% and its new value was (936) and performed all the steps of point 8. :</b>  \n",
    " \n",
    " ## #--The first hidden layer, add one node\n",
    " <img src=\"https://image.ibb.co/kGqZTS/Screenshot_from_2018_03_09_07_59_13.png\" alt=\"Drawing\" style=\"width: 900px;\"/>\n",
    "  \n",
    "\n",
    "## #--The secund hidden layer, add one node\n",
    " <img src=\"https://image.ibb.co/iQgBa7/Screenshot_from_2018_03_09_08_05_12.png\" alt=\"Drawing\" style=\"width: 900px;\"/>\n",
    "\n",
    " \n",
    "\n",
    "## #--The third hidden layer, add one node\n",
    " <img src=\"https://image.ibb.co/n5JDoS/Screenshot_from_2018_03_09_08_09_47.png\" alt=\"Drawing\" style=\"width: 900px;\"/>\n",
    "\n",
    " \n",
    " \n",
    " \n",
    "<b>Coment:</b>  In general, this neural network during the different modifications of the parameters of the nerural network, the parameter that generated the most effects or modified the result were  the activation function and the number of Eposh and the number of (blocks). When making changes to those data I could notice the difference between the results in both the loss graph and the loss variable. in the case that I did not see much difference was when I added more 1 node to each layer, I guess you can not notice much result because the added nodes were not many, only one was for each layer.\n",
    "Another important aspect were that when adding a node to all the layers, the behavior of the graph was a little different, where it can be seen that the test had a difference in relation to the training, considering the past graphs that are almost not noticed as much difference.\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
